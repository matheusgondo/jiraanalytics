{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "JiraAnalytics.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN5O56lhNgxD+qcufUAJE2I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matheusgondo/jiraanalytics/blob/main/JiraAnalytics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDi9lWOV3rho"
      },
      "source": [
        "Environment setup and file download - Google Drive\n",
        "\n",
        "Load libraries\n",
        "\n",
        "Jira: Library used to access Jira\n",
        "\n",
        "Panda: Library used for data manipulation and analysis.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzAMXRxJ3ZqB"
      },
      "source": [
        "!pip install jira\n",
        "!pip install -U -q PyDrive\n",
        "\n",
        "#Import the libraries that will be used\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "from collections import Counter\n",
        "from typing import cast\n",
        "\n",
        "from jira import JIRA\n",
        "from jira.client import ResultList\n",
        "from jira.resources import Issue\n",
        "\n",
        "#set gdrive access to save data\n",
        "from google.colab import drive\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# import matplotlib.pyplot as plt\n",
        "# import seaborn as sns\n",
        "# import math\n",
        "import datetime \n",
        "import json\n",
        "\n",
        "pd.options.display.float_format = '{}'.format\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUjGQISv3foV"
      },
      "source": [
        "#jira methods\n",
        "def init_jira(jiraServer,email,token):\n",
        "  jira = JIRA(server=jiraServer, basic_auth=(email,token))\n",
        "  return jira\n",
        "\n",
        "def search_issues(jql,expand_changelog):\n",
        "  issues = []\n",
        "  n = 0\n",
        "  if(expand_changelog):\n",
        "    while True:\n",
        "      tempissues = ResultList\n",
        "      tempissues = jira.search_issues(jql,expand=\"changelog\", json_result=True,maxResults=100,startAt=n)\n",
        "      n+=100\n",
        "      if not tempissues[\"issues\"]:\n",
        "        break\n",
        "      else:\n",
        "        issues.extend(tempissues[\"issues\"])\n",
        "  else:\n",
        "    while True:\n",
        "      tempissues = ResultList\n",
        "      tempissues = jira.search_issues(jql,json_result=True,maxResults=100,startAt=n)\n",
        "      n+=100\n",
        "      if not tempissues[\"issues\"]:\n",
        "        break\n",
        "      else:\n",
        "        issues.extend(tempissues[\"issues\"])\n",
        "  return issues\n",
        "\n",
        "def get_comments(id):\n",
        "  commments = ResultList\n",
        "  commments = jira.comments(id)\n",
        "  return commments\n",
        "\n",
        "def get_statuses():\n",
        "  statuses = ResultList\n",
        "  statuses = jira.statuses()\n",
        "  return statuses\n",
        "\n",
        "#fill dataframes\n",
        "def issues_df(issues):\n",
        "  keys = []\n",
        "  summaries = []\n",
        "  statuses = []\n",
        "  timesspent = []\n",
        "  issuetypes = []\n",
        "  createddates = []\n",
        "  sprints = []\n",
        "  for issue in issues:\n",
        "    sprintnames = \"\"\n",
        "    keys.append(issue[\"key\"])\n",
        "    summaries.append(issue[\"fields\"][\"summary\"])\n",
        "    statuses.append(issue[\"fields\"][\"status\"][\"name\"])\n",
        "    timesspent.append(datetime.timedelta(seconds=issue[\"fields\"][\"aggregatetimespent\"]+issue[\"fields\"][\"timespent\"] if issue[\"fields\"][\"aggregatetimespent\"] and issue[\"fields\"][\"timespent\"] else 0))\n",
        "    issuetypes.append(issue[\"fields\"][\"issuetype\"][\"name\"])\n",
        "    createddates.append(issue[\"fields\"][\"created\"])\n",
        "  df = pd.DataFrame({\"key\":keys,\"summary\":summaries,\"status\":statuses,\"timespent\":timesspent,\"issuetype\":issuetypes, \"created\":createddates})\n",
        "  df[\"timespent\"].fillna(pd.Timedelta(seconds=0))\n",
        "  return df\n",
        "\n",
        "def comments_df(keys):  \n",
        "  comment_keys = []\n",
        "  authors = []\n",
        "  createddates = []\n",
        "  bodies = []\n",
        "  for key in keys:\n",
        "    for comment in get_comments(key):\n",
        "      comment_keys.append(key)\n",
        "      authors.append(comment.author)\n",
        "      createddates.append(comment.created)\n",
        "      bodies.append(comment.body)\n",
        "  df = pd.DataFrame({\"key\":comment_keys,\"author\":authors,\"created date\":createddates,\"body\":bodies})\n",
        "  return df\n",
        "  \n",
        "def changelog_df(issues):  \n",
        "  keys = []\n",
        "  authorsnames = []\n",
        "  authorsids = []\n",
        "  dates = []\n",
        "  fields = []\n",
        "  fieldstype = []\n",
        "  fieldsId = []\n",
        "  froms = []\n",
        "  fromStrings  = []\n",
        "  tos = []\n",
        "  toStrings = []\n",
        "  for issue in issues:\n",
        "      if issue[\"changelog\"][\"total\"] >0:\n",
        "        for history in issue[\"changelog\"][\"histories\"] :\n",
        "          for item in history[\"items\"] :\n",
        "            keys.append(issue[\"key\"])\n",
        "            authorsnames.append(history[\"author\"][\"displayName\"])\n",
        "            authorsids.append(history[\"author\"][\"accountId\"])\n",
        "            dates.append(history[\"created\"])\n",
        "            fields.append(item[\"field\"])\n",
        "            fieldstype.append(item[\"fieldtype\"])\n",
        "            if \"fieldId\" in item:\n",
        "              fieldsId.append(item[\"fieldId\"])\n",
        "            else:\n",
        "              fieldsId.append(\"\")\n",
        "            froms.append(item[\"from\"])\n",
        "            fromStrings.append(item[\"fromString\"])\n",
        "            tos.append(item[\"to\"])\n",
        "            toStrings.append(item[\"toString\"])\n",
        "  df = pd.DataFrame({\"key\":keys,\"displayName\":authorsnames,\"accountId\":authorsids,\"created\":dates,\"field\":fields,\"fieldtype\":fieldstype,\"fieldId\":fieldsId,\"from\":froms,\"fromString\":fromStrings,\"to\":tos,\"toString\":toStrings})\n",
        "  return df\n",
        "\n",
        "  \n",
        "\n",
        "def transitions_df(changelogdf,issuesdf):  \n",
        "  create_transitions = issuesdf.copy()\n",
        "  create_transitions['toString'] = 'Product Backlog/To Do'\n",
        "  transitions = changelogdf.loc[changelogdf[\"field\"] == \"status\"]\n",
        "  transitions = pd.concat([transitions, create_transitions])\n",
        "  transitions = transitions.sort_values('created').drop_duplicates(subset=['key', 'toString'], keep='last')\n",
        "  statuses = transitions.sort_values(\"created\").pivot(index='key',values='created',columns='toString')\n",
        "  statuses = statuses.astype('datetime64[ns]')\n",
        "  statuses = statuses[transitions.sort_values('created').drop_duplicates(subset=['toString'], keep='first')[\"toString\"]]\n",
        "  return statuses"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kCiBaY33jbO"
      },
      "source": [
        "jiraServer = \"\"\n",
        "email = \"\"\n",
        "token = \"\"\n",
        "jql = \"\"\n",
        "\n",
        "#init\n",
        "jira = init_jira(jiraServer,email,token)\n",
        "\n",
        "issues = json.loads(json.dumps(search_issues(jql,True)))\n",
        "\n",
        "keys = []\n",
        "for issue in issues[\"issues\"]:\n",
        "  keys.append(issue[\"key\"])\n",
        "\n",
        "#simplified issues view\n",
        "issuesdf = issues_df(issues)\n",
        "\n",
        "#retrieve comments\n",
        "commentsdf = comments_df(keys)\n",
        "\n",
        "#retrieve changelog expanded\n",
        "changelogdf = changelog_df(issues)\n",
        "  \n",
        "#leadtime\n",
        "transitionsdf = transitions_df(changelogdf,issuesdf)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ra-_YuIG3lxg"
      },
      "source": [
        "#Allows a more interactive dynamic filter\n",
        "%reload_ext google.colab.data_table\n",
        "#issuesdf#.groupby(['issuetype'])['timespent'].sum() \n",
        "#commentsdf\n",
        "#calc lead time (interval between two statuses) \n",
        "#transitionsdf['in development [s]'] = (transitionsdf['In Development'] - transitionsdf['Developed']).apply(lambda x: x.seconds)\n",
        "\n",
        "#save CSV in gdrive\n",
        "transitionsdf.to_csv(r'/content/gdrive/MyDrive/jiraAnalytics/export_dataframe.csv', index = False, header=True)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJhUtFYK8A67"
      },
      "source": [
        "timespentdf =  issuesdf.groupby(['issuetype'])['timespent'].sum().reset_index(name ='Total timespent')\n",
        "timespentdf[\"Total timespent\"] = pd.to_timedelta(timespentdf[\"Total timespent\"])\n",
        "timespentdf['Total timespent'] = pd.to_numeric(timespentdf['Total timespent'].dt.total_seconds(), downcast='integer')\n",
        "\n",
        "ax = timespentdf.plot.bar(x='issuetype', y='Total timespent', rot=0,figsize=(17,12))\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}